{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65569af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def freedman(data):\n",
    "    # freedman method for choosing no of bins\n",
    "    data = np.asarray(data, dtype=np.float_)\n",
    "    IQR = scipy.stats.iqr(data, rng=(25, 75), scale=1, nan_policy=\"omit\")\n",
    "    N = data.size\n",
    "    bw = (2 * IQR) / np.power(N, 1/3)\n",
    "    mini= np.min(data)\n",
    "    maxi=np.max(data)\n",
    "    d = maxi-mini\n",
    "    result = int((d / bw) + 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4516118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all csv files using pandas\n",
    "PATH = '../datasets/'\n",
    "Study_A = pd.read_csv(PATH+\"Study_A.csv\")\n",
    "Study_B = pd.read_csv(PATH+\"Study_B.csv\")\n",
    "Study_C = pd.read_csv(PATH+\"Study_C.csv\")\n",
    "Study_D = pd.read_csv(PATH+\"Study_D.csv\")\n",
    "Study_E = pd.read_csv(PATH+\"Study_E.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd757dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies = pd.concat([Study_A,Study_B,Study_C,Study_D,Study_E]) \n",
    "# considering all given studies as we have data of PANSS_Score and visit days for all studies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62875bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies[\"P_total\"] = np.sum(np.array([all_studies[f\"P{i}\"] for i in range(1,8)]),axis=0)\n",
    "all_studies[\"N_total\"] = np.sum(np.array([all_studies[f\"N{i}\"] for i in range(1,8)]),axis=0)\n",
    "all_studies[\"G_total\"] = np.sum(np.array([all_studies[f\"G{i}\"] for i in range(1,8)]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f079d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies_control = all_studies[all_studies[\"TxGroup\"]==\"Control\"]\n",
    "all_studies_treatment = all_studies[all_studies[\"TxGroup\"]!=\"Control\"]\n",
    "# grouping all studies A,B...E depending on the treatment or control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc8f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamesh\\AppData\\Local\\Temp\\ipykernel_14600\\3013508270.py:6: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  all_studies.loc[:,\"Country\"] = encoded\n",
      "C:\\Users\\Hamesh\\AppData\\Local\\Temp\\ipykernel_14600\\3013508270.py:7: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  all_studies.loc[:,\"TxGroup\"] = encoded1\n"
     ]
    }
   ],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "arr = np.array(all_studies[\"Country\"]).reshape(-1,1)\n",
    "arr1 = np.array(all_studies[\"TxGroup\"]).reshape(-1,1)\n",
    "encoded = ordinal_encoder.fit_transform(arr)\n",
    "encoded1 = ordinal_encoder.fit_transform(arr1)\n",
    "all_studies.loc[:,\"Country\"] = encoded\n",
    "all_studies.loc[:,\"TxGroup\"] = encoded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a54905",
   "metadata": {},
   "outputs": [],
   "source": [
    "Study_A_grouped = []\n",
    "same_id = Study_A.iloc[0,:][\"PatientID\"] # initialized id\n",
    "dummy = []\n",
    "\n",
    "dummy.append(Study_A.iloc[0,:])\n",
    "\n",
    "for index,row in Study_A.iloc[1:,:].iterrows():\n",
    "    if(row[\"PatientID\"]!=same_id):\n",
    "        Study_A_grouped.append(dummy)\n",
    "        dummy=[]\n",
    "        dummy.append(row)\n",
    "        same_id = row[\"PatientID\"]\n",
    "    else:\n",
    "        dummy.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6accd97d",
   "metadata": {},
   "source": [
    "### PATIENT SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617187e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies_treatment_initial = all_studies_treatment[all_studies_treatment[\"VisitDay\"]==0] # rows with baseline measurement\n",
    "all_studies_control_initial = all_studies_control[all_studies_control[\"VisitDay\"]==0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb293d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
